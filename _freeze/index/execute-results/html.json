{
  "hash": "55686a99448ae0268386f19871926af2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Cicada Data\"\nsubtitle: \"Data analysis reproduction concerning the cicada's genome.\"\n\nauthor: \n    - name: \"Eric Mossotti\"\n      corresponding: true\n      email: ecmossotti@gmail.com\n      roles:\n        - Data analysis\n\nkeywords: \n    - Genome Assembly\n    - ETL Pipeline\n    - Python\n    - R\n    - Bash\n\ndate: 07/15/2024\ndate-modified: last-modified\ndate-format: \"MMM D, YYYY\"\n\nbibliography: references.bib\n\nrepo: https://github.com/ericMossotti/Cicada_Data\nsource: index.qmd\n\n\nabstract-title: \"Objective\"\nabstract: |\n      To reproduce DNA Zoo's summary table on the 17-year cicada.\n      \ndescription-meta: \"Reproducible genomics analysis.\"\n\nlicense: CC BY-SA\nfunding: \"The author(s) received no specific funding for this work.\"\n\ncsl: csl/apa.csl\ncitation-location: margin\ncitations-hover: true\nlink-citations: true\nciteproc: true\n\ntoc-expand: true\ntoc: true\nnumber-sections: true\ntoc-float: true\n\nlink-external-newwindow: true\nsmooth-scroll: true\nfig-responsive: true\necho: true\ncallout-appearance: simple\ncode-fold: true\ncode-overflow: wrap\n\nfilters:\n     - nutshell\n\n# For favicon support on most platforms\n# Generated the image at https://svg.io/\n# Converted to favicon package at https://realfavicongenerator.net/\ninclude-in-header:\n  text: |\n    <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"favicon/apple-touch-icon.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"favicon/favicon-32x32.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"favicon/favicon-16x16.png\">\n    <link rel=\"manifest\" href=\"favicon/site.webmanifest\">\n    <link rel=\"mask-icon\" href=\"favicon/safari-pinned-tab.svg\" color=\"#5bbad5\">\n    <meta name=\"msapplication-TileColor\" content=\"#da532c\">\n    <meta name=\"theme-color\" content=\"#ffffff\">\n    \n---\n\n\n\n## Introduction {.unnumbered}\n\n[The full repo for this project with instructions on how to replicate and run with near verbatim output.](https://github.com/ericMossotti/Cicada_Data)\n\n### Problem {.unnumbered}\n\nThe steps involved in reproducing data can be unclear.\n\n### Purpose {.unnumbered}\n\nTo elaborate on the objective stated at the top of this document, I seek to supplement DNA Zoo's report with an accessible data analysis (DA) pipeline. To accomplish this, I independently reproduce the original article's table while documenting every data processing step. Although there's nothing wrong with the original works, things can always be taken further. [@dnazoo], [@magicica]\n\n### Stakeholders {.unnumbered}\n\nThis might be of interest to the original authors of the article. More generally, the spirit of this work could transfer to other domains of data intensive research and analytics.\n\n### Source {.unnumbered}\n\nAll data used within this report was freely available from a public database hosted by DNA Zoo. [@dnazoo.s]\n\n### Pipeline {.unnumbered .column-screen-right}\n\n\n\n```{mermaid}\n%%| code-fold: true\n%%| code-summary: Create a Mermaid diagram from code.\n\nflowchart TB\n    A((1)):::circle --> B((2)):::circle\n    B --> C((3)):::circle\n    C --> D((4)):::circle\n\n    subgraph Extract [\"1. Extract\"]\n        direction LR\n        A1[\"directorize.py\"] --> A2[\"importer.py\"]\n    end\n    subgraph Transform [\"2. Transform\"]\n      direction TB\n      B1{\"decompress.py\"} -.->|.fasta| B2[\"assembly_stats\"] -.->|summary_stats.txt| B3[\"assemblyFramer.py\"]\n      B1 -.->|.fasta| B4[\"assemblyDictionary.py\"]\n    end\n    subgraph Load [\"3. Load\"]\n        direction TB\n        C1{\"strint.py\"}\n    end\n    subgraph Present [\"4. Present\"]\n        direction TB\n        D1[\"DNA Zoo's Table, Reproduced\"]\n    end\n\t\n    A ~~~ Extract\n    B ~~~ Transform\n    C ~~~ Load\n    D ~~~ Present\n\t\n    A2 -.->|fasta.gz| B1\n    B3 -.->|dataframe| C1\n    B4 -.->|dict| C1\n    C1 -.->|strings| Present\n    C1 -.->|strings| Present\n    \n```\n\n\n\n## Extract\n\nThis would be the data extraction phase of the DA pipeline.\n\n### Create Project Directory\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"A function used further below to establish the project's DA directory.\"}\n# Automates creation of the DA pipeline directory needed for this project to avoid confusion for those replicating this project, if desired.\n\nimport os\n\ndef directorize(base_path, structure):\n    # Nested directories\n    for dir_name, subdirs in structure.items():\n        dir_path = os.path.join(base_path, dir_name)\n        os.makedirs(dir_path, exist_ok = True)\n\n        for subdir in subdirs:\n            subdir_path = os.path.join(dir_path, subdir)\n            os.makedirs(subdir_path, exist_ok = True)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"If the directory folders already exist, it shouldn't cause any issues to allow this code to evaluate during render.\"}\n# Define the directory structure\nstructure = {\n    \"01_Extract/\": [\"data/\", \"scripts/\"],\n    \"02_Transform/\": [\"data/\", \"scripts/\"],\n    \"03_Load/\": [\"data/\", \"scripts/\"],\n    \"04_Present/\": [\"data/\", \"scripts/\"]\n}\n\n# Create the analysis folder structure in a preferred base directory\n# \"\" = project's working directory\ndirectorize(\"\", structure)\n```\n:::\n\n\n\n### Download to Local Machine\n\nIf you want the exact verbatim output, then delete the cloned folder structure (01_Extract through the 04_Present and run this code).\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Importing all scripts and data needed for the project from the web to make things easier for replicating this project. If you want the exact verbatim output, then delete the cloned folder structure (01_Extract through the 04_Present and run this code). Otherwise, it's ok to re-run this with the scripts already there.\"}\n# ---- Import data from the web with wget\nimport os\nimport sys\nimport wget\n\ndef importer (fileMap):\n    # Download from URL to path and notify when complete\n    for url, file_path in fileMap.items():\n        # Checking file existence\n        if not os.path.exists(file_path):\n            wget.download(url, file_path)\n            print(f\"{file_path} written\")\n        else:\n            print(f\"{file_path} already exists.\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Run `importer()`, passing in the mapped URLs keys to their local directory path destination values.\"}\n# Set the url\nfasta_URL = \"https://dnazoo.s3.wasabisys.com/Magicicada_septendecula/magicicada_hifiasm.asm.bp.p_ctg_HiC.fasta.gz\"\n# Set the desired local file path\nfasta_PATH = \"01_Extract/data/magicicada.fasta.gz\"\n\ndecompress_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/02_Transform/scripts/decompress.py\"\ndecompress_PATH = \"02_Transform/scripts/decompress.py\"\n\nasmblydict_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/02_Transform/scripts/assemblyDictionary.py\"\nasmblydict_PATH = \"02_Transform/scripts/assemblyDictionary.py\"\n\nasmblyframe_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/02_Transform/scripts/assemblyFramer.py\"\nasmblyframe_PATH = \"02_Transform/scripts/assemblyFramer.py\"\n\nstrint_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/03_Load/scripts/strint.py\"\nstrint_PATH = \"03_Load/scripts/strint.py\"\n\nformaframe_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/04_Present/scripts/formaFrame.py\"\nformaframe_PATH = \"04_Present/scripts/formaFrame.py\"\n\nextractIgnore_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/01_Extract/data/.gitignore\"\nextractIgnore_PATH = \"01_Extract/data/.gitignore\"\n\ntransformIgnore_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/02_Transform/data/.gitignore\"\ntransformIgnore_PATH = \"02_Transform/data/.gitignore\"\n\n\n# Map the url to the file path\nfileMap = {\n  fasta_URL: fasta_PATH,\n  decompress_URL: decompress_PATH,\n  asmblydict_URL: asmblydict_PATH,\n  asmblyframe_URL: asmblyframe_PATH,\n  strint_URL: strint_PATH,\n  formaframe_URL: formaframe_PATH,\n  extractIgnore_URL: extractIgnore_PATH,\n  transformIgnore_URL: transformIgnore_PATH\n  }\n\nimporter(fileMap)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n01_Extract/data/magicicada.fasta.gz written\n02_Transform/scripts/decompress.py written\n02_Transform/scripts/assemblyDictionary.py written\n02_Transform/scripts/assemblyFramer.py written\n03_Load/scripts/strint.py written\n04_Present/scripts/formaFrame.py written\n01_Extract/data/.gitignore written\n02_Transform/data/.gitignore written\n```\n\n\n:::\n:::\n\n\n\n\n\n::: callout-note\n### The specific link used to download all data from\n\n<https://dnazoo.s3.wasabisys.com/Magicicada_septendecula/magicicada_hifiasm.asm.bp.p_ctg_HiC.fasta.gz>\n:::\n\n## Transform\n\nThe data transformation phase of the pipeline.\n\n### Decompress .GZ\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"Source the `decompress.py` script.\"}\nreticulate::source_python(\"02_Transform/scripts/decompress.py\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Transform the compressed file to its decompressed form.\"}\n# ---- Decompress the gz file with gzip\n\nimport os\nimport gzip\nimport shutil\n\ndef decompress(gzFasta, fasta):\n    \n    # If not decompressed, then decompress and redirect to a new file path\n    if not os.path.exists(fasta):\n        # File doesn't exist, then decompress\n        with gzip.open(gzFasta, 'rb') as f_in:\n            with open(fasta, 'wb') as f_out:\n                shutil.copyfileobj(f_in, f_out)\n        print(f\"{fasta} has been decompressed and written.\")\n    else:\n        print(f\"The file {fasta} already exists. Skipping unzip.\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Run `decompress()`, using the compressed path and the desired path to the decompressed file.\"}\n# Set the compressed fasta.gz file variable\ngzFasta = \"01_Extract/data/magicicada.fasta.gz\"\n\n# Set the decompressed fasta file variable\nfasta = \"02_Transform/data/magicicada.fasta\"\n\n# Pass file paths to the function\ndecompress(gzFasta, fasta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n02_Transform/data/magicicada.fasta has been decompressed and written.\n```\n\n\n:::\n:::\n\n\n\n### FASTA to Text, to DataFrame\n\nSourcing the dataframe formatting script here, as there is some issue with knitr engine and Python with these parts. Seems like some kind of conflict with switching between dataframe and dictionary data types.\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"Source the `formaFrame.py` script.\"}\nreticulate::source_python(\"04_Present/scripts/formaFrame.py\")\n```\n:::\n\n\n\nThis chunk should be ran locally instead of with `quarto render`. When working with the source file, change the code-chunk language specifier from `{.bash}` back to `{bash}`. You might have to add the `{bash}` tag entirely back to the div. Not sure how else to go about accomplishing this within my current Quarto project setup. [@trizna2020]\n\n``` {.bash}\n# BASH SCRIPT\n\n# The uncompressed fasta file variable\nfasta=02_Transform/data/magicicada.fasta\n\n# The text file path variable generated by the script\nsummary_stats=02_Transform/data/summary_stats.txt\n\nassembly_stats $fasta > $summary_stats\n```\n\n\nI need to do this for the rendering part to display the code-cell outputs how I wanted them to. However, you can use the bash code chunk further below and comment this code out if you want. This makes it so you can deactivate the bash code chunk for render but still have everything else work without a hitch if you go simply from empty directory to render with this document. \n\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Instead, using the file from running the assembly_stats Python program as a Bash command pre-render.\"}\nsummaryStats_URL = \"https://raw.githubusercontent.com/ericMossotti/Cicada_Data/main/02_Transform/data/summary_stats.txt\"\n\nsummaryStats_PATH = \"02_Transform/data/summary_stats.txt\"\n\nmap_summary = {summaryStats_URL: summaryStats_PATH}\n\nimporter(map_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n02_Transform/data/summary_stats.txt written\n```\n\n\n:::\n:::\n\n\n\n\nNow, transform the text file into a Python dataframe. I am opting not to blanket change data-types as output format could vary by user preference.\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"Source the `assemblyFramer.py` script.\"}\n# Import external python script to local library environment\nreticulate::source_python(\"02_Transform/scripts/assemblyFramer.py\")\n```\n:::\n\n\n\n::: scroll-code\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Transform the text file data into a mult-indexed dataframe. Multi-indexing simplifies query syntax later on.\"}\n\"\"\" Utilizes Python string methods and multi-indexing \nto process assembly_stats' output text file \"\"\"\n\nimport pandas as pd\nimport re\n\ndef assemblyFramer(statsPath = None):\n    \n    #---- Read Text File\n    with open(statsPath, 'r') as file:\n        content = file.read()\n        \n    #---- Regex Matching\n    pairs = re.findall(r\"\\\"\\w+\\\"\\:\\s\\d*\\.?\\d*\", content)\n    \n    #---- Clean Strings\n    cleaned_list = [pair.replace('\"', '').replace(':', '').strip() for pair in pairs]\n    \n    #---- Split Strings\n    labeled_list = [item.split() for item in cleaned_list]\n    \n    #---- Create DataFrame\n    df = pd.DataFrame(labeled_list, columns = ['Label', 'Value'])\n    \n    #---- Add Category Column\n    df['Category'] = ['Contigs'] * 17 + ['Scaffolds'] * 17\n    \n    #---- Create Arrays\n    category_array = pd.Series.to_list(df['Category'])\n    label_array = pd.Series.to_list(df['Label'])\n    value_array = pd.Series.to_list(df['Value'])\n    \n    #---- Combine Arrays to List\n    arrayList = [category_array, label_array]\n    \n    #---- Define Multi-Level Indices\n    indices = pd.MultiIndex.from_arrays(arrays = arrayList, names = ('Category', 'Label'))\n    \n    #---- Index a DataFrame \n    df_indexed = pd.DataFrame(data = value_array, index = indices)\n    \n    #---- Rename Non-Indexed Column\n    df_indexed = df_indexed.rename(columns = {0:\"Value\"})\n    \n    return df_indexed\n```\n:::\n\n\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Run `assemblyFramer()`, passing in the path to the text file generated by running the Bash script from earlier.\"}\n# Set the local text file path\nstatsPath = \"02_Transform/data/summary_stats.txt\"\n# Run to yield a multi-indexed dataframe\ndf = assemblyFramer(statsPath)\n```\n:::\n\n\n\n### FASTA to Dictionary\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"Source the external `assemblyDictionary.py` script.\"}\nreticulate::source_python(\"02_Transform/scripts/assemblyDictionary.py\")\n```\n:::\n\n\n\n::: scroll-code\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Return a stats dictionary.\"}\n\"\"\"\nParsing genomic data in a memory-efficent way by not loading the entire\nfile into memory at once. The file is processed one line at a time, grouping\nrelated lines together. \n\nStatistics such as N50 are crucial in assessing the contiguity \nof a genome assembly, with higher N50 values generally indicating \na more contiguous assembly.\n\nThe distinction between contigs and scaffolds is important in genome assembly, \nas it provides information about the continuity and completeness of \nthe assembly.\n\n\n#----\nread_genome()\n____________\n\nDifferentiates between scaffolds (which may contain gaps) and contigs \n(continuous sequences). \n  \nCalculate the GC content, which is an important genomic characteristic.\nPrepare lists of contig and scaffold lengths.\n\n\n#----\nfasta_iter()\n____________\n\nGroups the .fasta file data into alternating groups of headers and sequences.\nIt is a generator function that will pause until the next item is requested \nafter yielding a tuple.\n\nThe iterator groups two aspects:\n  a. Single header lines starting with '>'\n  b. Subsequent lines until the next '>'\n\n\n#----\ncalculate_stats()\n_________________\n\nWhere the stats dictionary values are calculated and keys assigned.\n\n\n#----\ndef assemblyDictionary()\n________________________\n\nMaps the previously created dictionaries of contig and scaffold stats to the \ncategory they belong, thereby distinguishing the contigs and scaffold stats. \nReturning the desired values is quite intuitive as a result.\n\n\n\"\"\"\n\nimport numpy as np\nfrom itertools import groupby\n\n#---- fasta_iter()\ndef fasta_iter(fasta_file):\n    \n    fh = open(fasta_file)\n    \n    # Only need the second part, or code sequences part, of the grouped by items\n    fa_iter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n    \n    for header in fa_iter:\n        \n        # Get first line of group; drop the \">\" and starting/trailing whitespace\n        header = next(header)[1:].strip()\n        \n        # Join all sequence lines to one string; conv to uppercase; remv whitespace\n        seq = \"\".join(s.upper().strip() for s in next(fa_iter))\n        \n        yield header, seq\n\n\n#---- read_genome\ndef read_genome(fasta_file):\n    \n    gc = 0\n    total_len = 0\n    \n    contig_lens = []\n    scaffold_lens = []\n    \n    # Ignore header information (the '_' part) and process sequence data\n    for _, seq in fasta_iter(fasta_file):\n        \n        # Add sequence (scaffold) length\n        scaffold_lens.append(len(seq))\n        # NN reprs gaps in scaffold, which are contigs\n        if \"NN\" in seq:\n            # Add split sequences to contig list if gap\n            contig_list = seq.split(\"NN\")\n            \n        else:\n            # Add sequence to contig list\n            contig_list = [seq]\n            \n        for contig in contig_list:\n            # An initial check for 0-length contigs\n            if len(contig):\n              gc += contig.count('G') + contig.count('C')\n              # Update the total length\n              total_len += len(contig)\n              # Add  length to list of contig lengths\n              contig_lens.append(len(contig))\n    # GC content as the percentage of total genome\n    gc_cont = (gc / total_len) * 100\n\n    return contig_lens, scaffold_lens, gc_cont\n\n\n#---- calculate_stats()\ndef calculate_stats(seq_lens, gc_cont):\n    \n    # Empty dictionary\n    stats = {}\n    # The set of sequence lengths are converted to a NumPy array\n    seq_array = np.array(seq_lens)\n    \n    # Count the individual sequences\n    stats['sequence_count'] = seq_array.size\n    \n    # GC proportion\n    stats['gc_content'] = gc_cont\n\n    # Sort lengths by descending order\n    sorted_lens = seq_array[np.argsort(-seq_array)]\n    \n    # The first length is the longest due to sorting\n    stats['longest'] = int(sorted_lens[0])\n    \n    # Likewise, shortest length is at the end\n    stats['shortest'] = int(sorted_lens[-1])\n    \n    stats['median'] = np.median(sorted_lens)\n    \n    stats['mean'] = np.mean(sorted_lens)\n    \n    # Sums the total length of all sequences\n    stats['total_bps'] = int(np.sum(sorted_lens))\n    \n    # An array of cumulative sums to calculate N50 efficiently\n    csum = np.cumsum(sorted_lens)\n    \n    for level in [10, 20, 30, 40, 50]:\n        \n        # Calculate target base pair count for the level\n        nx = int(stats['total_bps'] * (level / 100))\n        \n        # Find smallest bp value in array, >= to the target %\n        csumn = min(csum[csum >= nx])\n        \n        \"\"\"\n        \n        --- The original code in the next line:\n  \n          l_level = int(np.where(csum == csumn)[0])\n          \n        --- Has been changed to:\n            \n          l_level = int(np.where(csum == csumn)[0][0])\n\n        This finds the index where the cumulative sum equals csumn, which \n        represents the number of sequences needed to reach the target \n        percentage of base pairs. \n        \n        I've added an extra [0] to fix the NumPy deprecation warning. This \n        ensures return of a scalar value from the array, as the extra '[0]' \n        ensures the first element of the first array is being accessed.\n        \n        The console warning (in Rstudio) that's now been resolved: \n        \n          'Conversion of an array with ndim > 0 to a scalar is deprecated, and \n          will error in future. Ensure you extract a single element from your \n          array before performing this operation. (Deprecated NumPy 1.25.)'\n          \n        \"\"\"\n        \n        # Determine the index where the sequences required to reach target % of bps is met\n        l_level = int(np.where(csum == csumn)[0][0])\n        \n        # Get bp length of seq at index, l_level, for the N-statistic value\n        n_level = int(sorted_lens[l_level])\n        \n        stats['L' + str(level)] = l_level\n\n        # Store the statistic in a dictionary, mapped to its new name key\n        stats['N' + str(level)] = n_level\n        \n    return stats\n\n\n#---- assemblyDictionary\ndef assemblyDictionary(infilename):\n    \n    # Return two np arrays of lengths\n    contig_lens, scaffold_lens, gc_cont = read_genome(infilename)\n    \n    # Return contig stats from contig lengths\n    contig_stats = calculate_stats(contig_lens, gc_cont)\n    \n    # Return scaffold stats from scaffold lengths\n    scaffold_stats = calculate_stats(scaffold_lens, gc_cont)\n    \n    # A dictionary of outputs is easily queried\n    stat_output = {'Contig Stats': contig_stats,\n                   'Scaffold Stats': scaffold_stats}\n    \n    return stat_output\n```\n:::\n\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"Source the `strint.py` script.\"}\nreticulate::source_python(\"03_Load/scripts/strint.py\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Instead of a text file, this skips several time-consuming steps.\"}\nstatsDict = assemblyDictionary(\"02_Transform/data/magicicada.fasta\")\n```\n:::\n\n\n\n## Load\n\nThis is the data loading phase. Following completion of this stage, querying the data should be more intuitive than before.\n\n### Assign Variables with `strint.py`\n\n::: scroll-code\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"This code transforms the strings in the value column of the dataframe to a more visually appealing, thousands-separated form.\"}\n\"\"\" \nFormats the string representation of an \ninteger value as a comma separated string \n\"\"\"\n\nimport pandas as pd\nimport re\n\ndef strint(data, category, label):\n    if isinstance(data, pd.DataFrame):\n        # Existing DataFrame handling code\n        stat = data.loc[(category, label), \"Value\"]\n        \n        # Set boolean match value\n        isFloat = re.search(r\"\\.\", str(stat))\n        \n        # Convert to float if there is a decimal\n        if isFloat:\n            stat = pd.to_numeric(stat, downcast=\"float\")\n        else:\n            # Else convert to an integer \n            stat = pd.to_numeric(stat, downcast=\"integer\")\n    \n    elif isinstance(data, dict):\n        # New dictionary handling code\n        #stat = data.get(f\"{category} {label}\")\n        stat = data[category][label]\n        \n        if stat is None:\n            raise KeyError(f\"Key '{category} {label}' not found in the dictionary\")\n        \n        # No need to convert to numeric as values are already integers or floats\n    \n    else:\n        raise TypeError(\"Input must be a pandas DataFrame or a dictionary\")\n\n    # Add a thousands separator and convert back to a string\n    stat = f'{stat:,}'\n    \n    return stat\n```\n:::\n\n\n:::\n\n### DataFrame Input\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Call `strint()`, with the simpflified query syntax noted earlier. Then simply specify the literal 'Category' and 'Label' keys to return the desired value.\"}\n#---- Contigs\nctig_len = strint(df, \"Contigs\", \"total_bps\")\nctig_count = strint(df, \"Contigs\", \"sequence_count\")\nctig_n50 = strint(df, \"Contigs\", \"N50\")\nctig_max = strint(df, \"Contigs\", \"longest\")\n\n#---- Scaffolds\nsfld_len = strint(df, \"Scaffolds\", \"total_bps\")\nsfld_count = strint(df, \"Scaffolds\", \"sequence_count\")\nsfld_n50 = strint(df, \"Scaffolds\", \"N50\")\nsfld_max = strint(df, \"Scaffolds\", \"longest\")\n```\n:::\n\n\n\n::: {.callout-tip appearance=\"simple\"}\n#### Multi-index dataframe query syntax\n\n::: scroll-code\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"show\" code-summary=\"An example of the syntax used to query the multi-indexed dataframe. This code is not evaluated, but only for illustrative purposes.\"}\n\"\"\"\n\nstrint(dataframe, category, label)\n\ncategory options\n----------------\n  Contigs\n  Scaffolds\n\n\nlabel options\n----------------\n  L10\n  L20\n  L30\n  L40\n  L50\n  N10\n  N20\n  N30\n  N40\n  N50\n  gc_content\n  longest\n  mean\n  median\n  sequence_count\n  shortest\n  total_bps\n  \n\"\"\"\n\nctig_len = strint(df, \"Contigs\", \"N50\")\n\n# -->> Looking inside the strint(dataframe, category, label) function ---->>\n\n# Which then finds the desired value or 'Value'\nstat = dataframe.loc[(category, label), \"Value\"]\n```\n:::\n\n\n:::\n:::\n\n### Dictionary Input\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"Assigns the dictionary value as string objects.\"}\n#---- Contigs\nctig_len = strint(statsDict, \"Contig Stats\", \"total_bps\")\nctig_count = strint(statsDict, \"Contig Stats\", \"sequence_count\")\nctig_n50 = strint(statsDict, \"Contig Stats\", \"N50\")\nctig_max = strint(statsDict, \"Contig Stats\", \"longest\")\n\n#---- Scaffolds\nsfld_len = strint(statsDict, \"Scaffold Stats\", \"total_bps\")\nsfld_count = strint(statsDict, \"Scaffold Stats\", \"sequence_count\")\nsfld_n50 = strint(statsDict, \"Scaffold Stats\", \"N50\")\nsfld_max = strint(statsDict, \"Scaffold Stats\", \"longest\")\n```\n:::\n\n\n\n::: {.callout-tip appearance=\"simple\"}\n#### Dictionary query syntax\n\n::: scroll-code\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"show\" code-summary=\"An example of the syntax used to query the dictionary This code is not evaluated, but only for illustrative purposes.\"}\n\"\"\"\n\nstrint(dataframe, category, label)\n\ncategory options\n----------------\n  Contig Stats\n  Scaffold Stats\n\n\nlabel options\n----------------\n  L10\n  L20\n  L30\n  L40\n  L50\n  N10\n  N20\n  N30\n  N40\n  N50\n  gc_content\n  longest\n  mean\n  median\n  sequence_count\n  shortest\n  total_bps\n  \n\"\"\"\n\n# A look inside assemblyDictionary.py where stat_output is returned\nstat_output = {'Contig Stats': contig_stats,\n               'Scaffold Stats': scaffold_stats}\n\nctig_len = statsDict[\"Contig Stats\"][\"total_bps\"]\n```\n:::\n\n\n:::\n:::\n\n## Present\n\n### The Pandas Table\n\nThis is a slightly formatted view of the Pandas table designed to be more easily queried to return the desired statistic. If, however, you'd like to treat the Styler object as the unchanged, dataframe object, use the `forma_df.data` syntax.\n\n[:The original dataframe output:](#NutFrame)\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"The Pandas dataframe as a Styler object for better viewing.\"}\n# Display with Style \nforma_df = df.loc[:].style.pipe(formaFrame)\n\nforma_df\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_f8755\">\n  <caption>Assembly Stats</caption>\n  <thead>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_f8755_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"17\">Contigs</th>\n      <th id=\"T_f8755_level1_row0\" class=\"row_heading level1 row0\" >L10</th>\n      <td id=\"T_f8755_row0_col0\" class=\"data row0 col0\" >41</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row1\" class=\"row_heading level1 row1\" >L20</th>\n      <td id=\"T_f8755_row1_col0\" class=\"data row1 col0\" >99</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row2\" class=\"row_heading level1 row2\" >L30</th>\n      <td id=\"T_f8755_row2_col0\" class=\"data row2 col0\" >174</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row3\" class=\"row_heading level1 row3\" >L40</th>\n      <td id=\"T_f8755_row3_col0\" class=\"data row3 col0\" >267</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row4\" class=\"row_heading level1 row4\" >L50</th>\n      <td id=\"T_f8755_row4_col0\" class=\"data row4 col0\" >385</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row5\" class=\"row_heading level1 row5\" >N10</th>\n      <td id=\"T_f8755_row5_col0\" class=\"data row5 col0\" >12643769</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row6\" class=\"row_heading level1 row6\" >N20</th>\n      <td id=\"T_f8755_row6_col0\" class=\"data row6 col0\" >9681846</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row7\" class=\"row_heading level1 row7\" >N30</th>\n      <td id=\"T_f8755_row7_col0\" class=\"data row7 col0\" >7895799</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row8\" class=\"row_heading level1 row8\" >N40</th>\n      <td id=\"T_f8755_row8_col0\" class=\"data row8 col0\" >6288966</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row9\" class=\"row_heading level1 row9\" >N50</th>\n      <td id=\"T_f8755_row9_col0\" class=\"data row9 col0\" >4902968</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row10\" class=\"row_heading level1 row10\" >gc_content</th>\n      <td id=\"T_f8755_row10_col0\" class=\"data row10 col0\" >35.248103813419206</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row11\" class=\"row_heading level1 row11\" >longest</th>\n      <td id=\"T_f8755_row11_col0\" class=\"data row11 col0\" >43529772</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row12\" class=\"row_heading level1 row12\" >mean</th>\n      <td id=\"T_f8755_row12_col0\" class=\"data row12 col0\" >1552486.9914285715</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row13\" class=\"row_heading level1 row13\" >median</th>\n      <td id=\"T_f8755_row13_col0\" class=\"data row13 col0\" >331935.0</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row14\" class=\"row_heading level1 row14\" >sequence_count</th>\n      <td id=\"T_f8755_row14_col0\" class=\"data row14 col0\" >4200</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row15\" class=\"row_heading level1 row15\" >shortest</th>\n      <td id=\"T_f8755_row15_col0\" class=\"data row15 col0\" >1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row16\" class=\"row_heading level1 row16\" >total_bps</th>\n      <td id=\"T_f8755_row16_col0\" class=\"data row16 col0\" >6520445364</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level0_row17\" class=\"row_heading level0 row17\" rowspan=\"17\">Scaffolds</th>\n      <th id=\"T_f8755_level1_row17\" class=\"row_heading level1 row17\" >L10</th>\n      <td id=\"T_f8755_row17_col0\" class=\"data row17 col0\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row18\" class=\"row_heading level1 row18\" >L20</th>\n      <td id=\"T_f8755_row18_col0\" class=\"data row18 col0\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row19\" class=\"row_heading level1 row19\" >L30</th>\n      <td id=\"T_f8755_row19_col0\" class=\"data row19 col0\" >1</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row20\" class=\"row_heading level1 row20\" >L40</th>\n      <td id=\"T_f8755_row20_col0\" class=\"data row20 col0\" >2</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row21\" class=\"row_heading level1 row21\" >L50</th>\n      <td id=\"T_f8755_row21_col0\" class=\"data row21 col0\" >3</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row22\" class=\"row_heading level1 row22\" >N10</th>\n      <td id=\"T_f8755_row22_col0\" class=\"data row22 col0\" >1438277616</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row23\" class=\"row_heading level1 row23\" >N20</th>\n      <td id=\"T_f8755_row23_col0\" class=\"data row23 col0\" >1438277616</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row24\" class=\"row_heading level1 row24\" >N30</th>\n      <td id=\"T_f8755_row24_col0\" class=\"data row24 col0\" >915491830</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row25\" class=\"row_heading level1 row25\" >N40</th>\n      <td id=\"T_f8755_row25_col0\" class=\"data row25 col0\" >607508155</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row26\" class=\"row_heading level1 row26\" >N50</th>\n      <td id=\"T_f8755_row26_col0\" class=\"data row26 col0\" >518932092</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row27\" class=\"row_heading level1 row27\" >gc_content</th>\n      <td id=\"T_f8755_row27_col0\" class=\"data row27 col0\" >35.248103813419206</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row28\" class=\"row_heading level1 row28\" >longest</th>\n      <td id=\"T_f8755_row28_col0\" class=\"data row28 col0\" >1438277616</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row29\" class=\"row_heading level1 row29\" >mean</th>\n      <td id=\"T_f8755_row29_col0\" class=\"data row29 col0\" >3212576.533990148</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row30\" class=\"row_heading level1 row30\" >median</th>\n      <td id=\"T_f8755_row30_col0\" class=\"data row30 col0\" >62362.5</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row31\" class=\"row_heading level1 row31\" >sequence_count</th>\n      <td id=\"T_f8755_row31_col0\" class=\"data row31 col0\" >2030</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row32\" class=\"row_heading level1 row32\" >shortest</th>\n      <td id=\"T_f8755_row32_col0\" class=\"data row32 col0\" >1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_f8755_level1_row33\" class=\"row_heading level1 row33\" >total_bps</th>\n      <td id=\"T_f8755_row33_col0\" class=\"data row33 col0\" >6521530364</td>\n    </tr>\n  </tbody>\n</table>\n```\n\n:::\n:::\n\n\n\n### DNA Zoo's Table, Reproduced\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden  code-summary=\"To make the variable calls simpler in the table below.\"}\nlibrary(reticulate)\n```\n:::\n\n\n\nImporting the library makes it simpler for inserting the values into the table below. For example, I would have had to type ``{r} reticulate::py$ctig_n50``, but now, I only need to type ``{r} py$ctig_n50`` into the individual cells. I needed to convert the Python into R objects, as the knitr engine used in rendering this document does not seem to display output from execution of inline Python code directly.\n\n::: {#ZooTable}\n|                          |                         |                       |                           |\n|------------------|------------------|------------------|-------------------|\n| **Contig length (bp)**   | **Number of contigs**   | **Contig N50 (bp)**   | **Longest contig (bp)**   |\n| 6\\,520\\,445\\,364        | 4\\,200     | 4\\,902\\,968     | 43\\,529\\,772         |\n| **Scaffold length (bp)** | **Number of scaffolds** | **Scaffold N50 (bp)** | **Longest scaffold (bp)** |\n| 6\\,521\\,530\\,364        | 2\\,030     | 518\\,932\\,092     | 1\\,438\\,277\\,616        |\n:::\n\n\n## :x NutFrame {.unnumbered .unlisted}\n\n\n\n::: {.cell}\n\n```{.python .cell-code .hidden  code-summary=\"The dataframe object on display, in all its glory.\"}\n# The un-styled dataframe output\nforma_df.data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                       Value\nCategory  Label                             \nContigs   L10                             41\n          L20                             99\n          L30                            174\n          L40                            267\n          L50                            385\n          N10                       12643769\n          N20                        9681846\n          N30                        7895799\n          N40                        6288966\n          N50                        4902968\n          gc_content      35.248103813419206\n          longest                   43529772\n          mean            1552486.9914285715\n          median                    331935.0\n          sequence_count                4200\n          shortest                      1000\n          total_bps               6520445364\nScaffolds L10                              0\n          L20                              0\n          L30                              1\n          L40                              2\n          L50                              3\n          N10                     1438277616\n          N20                     1438277616\n          N30                      915491830\n          N40                      607508155\n          N50                      518932092\n          gc_content      35.248103813419206\n          longest                 1438277616\n          mean             3212576.533990148\n          median                     62362.5\n          sequence_count                2030\n          shortest                      1000\n          total_bps               6521530364\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}