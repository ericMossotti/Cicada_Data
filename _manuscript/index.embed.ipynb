{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cicada Data\n",
    "\n",
    "Data analysis reproduction concerning the cicada’s genome.\n",
    "\n",
    "Eric Mossotti  \n",
    "Jul 6, 2024\n",
    "\n",
    "To reproduce DNA Zoo’s summary table on the 17-year cicada.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Problem\n",
    "\n",
    "The steps involved in reproducing data can be unclear.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "To elaborate on the objective stated at the top of this document, the purpose is to supplement the DNA Zoo’s report with a more easily accessible data analysis (DA) pipeline. To accomplish this, I seek to independently reproduce and supplement their article’s table while supplying all data processing steps with documented code embedded in the report itself. Although there’s nothing wrong with the data or article, it could be taken further. \\[@dnazoo\\], \\[@magicica\\]\n",
    "\n",
    "### Stakeholders\n",
    "\n",
    "This might be of interest to the original authors of the article. More generally, the spirit of this work could transfer to other domains of data intensive research and analytics.\n",
    "\n",
    "### Source\n",
    "\n",
    "All data used within this report was freely available from a public database hosted by DNA Zoo. \\[@dnazoo.s\\]\n",
    "\n",
    "## Pipeline"
   ],
   "id": "977675c6-a36c-4ba6-a3a5-2db6e4e4fa3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "layout-align": "default"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "<pre class=\"mermaid mermaid-js\">\n",
       "flowchart TB\n",
       "    A((1)):::circle --&gt; B((2)):::circle\n",
       "    B --&gt; C((3)):::circle\n",
       "    C --&gt; D((4)):::circle\n",
       "    \n",
       "    subgraph Extract [&quot;1. Extract&quot;]\n",
       "        direction LR\n",
       "        A1[&quot;Create local\\nanalysis directory&quot;] --&gt; A2[&quot;Download from web\\nto local directory&quot;]\n",
       "    end\n",
       "    subgraph Transform [&quot;2. Transform&quot;]\n",
       "        direction LR\n",
       "        B1[&quot;Decompress\\nfasta.gz file&quot;] --&gt; B2[&quot;Output text file\\nusing bash script&quot;]\n",
       "        B2 --&gt; B3[&quot;Transform text to\\nindexed dataframe&quot;]\n",
       "    end\n",
       "    subgraph Load [&quot;3. Load&quot;]\n",
       "        direction LR\n",
       "        C1[&quot;Format table values\\nwith thousands-separator&quot;]\n",
       "    end\n",
       "    subgraph Present [&quot;4. Present&quot;]\n",
       "        direction LR\n",
       "        D1[&quot;Create a Styler object\\nfrom the dataframe&quot;] --&gt; D2[&quot;Dataframe is accessible\\nfrom the Styler object&quot;]\n",
       "        D2 --&gt; D3[&quot;Reproduce DNA Zoo table\\nusing Python to R conversion&quot;]\n",
       "    end\n",
       "    \n",
       "    A ~~~ Extract\n",
       "    B ~~~ Transform\n",
       "    C ~~~ Load\n",
       "    D ~~~ Present\n",
       "    \n",
       "    Extract -.-&gt;|fasta.gz| Transform\n",
       "    Transform -.-&gt;|pd.DataFrame| Load\n",
       "    Load -.-&gt;|string variables| Present\n",
       "\n",
       "</pre>"
      ]
     }
    }
   ],
   "source": [
    "flowchart TB\n",
    "    A((1)):::circle --> B((2)):::circle\n",
    "    B --> C((3)):::circle\n",
    "    C --> D((4)):::circle\n",
    "    \n",
    "    subgraph Extract [\"1. Extract\"]\n",
    "        direction LR\n",
    "        A1[\"Create local\\nanalysis directory\"] --> A2[\"Download from web\\nto local directory\"]\n",
    "    end\n",
    "    subgraph Transform [\"2. Transform\"]\n",
    "        direction LR\n",
    "        B1[\"Decompress\\nfasta.gz file\"] --> B2[\"Output text file\\nusing bash script\"]\n",
    "        B2 --> B3[\"Transform text to\\nindexed dataframe\"]\n",
    "    end\n",
    "    subgraph Load [\"3. Load\"]\n",
    "        direction LR\n",
    "        C1[\"Format table values\\nwith thousands-separator\"]\n",
    "    end\n",
    "    subgraph Present [\"4. Present\"]\n",
    "        direction LR\n",
    "        D1[\"Create a Styler object\\nfrom the dataframe\"] --> D2[\"Dataframe is accessible\\nfrom the Styler object\"]\n",
    "        D2 --> D3[\"Reproduce DNA Zoo table\\nusing Python to R conversion\"]\n",
    "    end\n",
    "    \n",
    "    A ~~~ Extract\n",
    "    B ~~~ Transform\n",
    "    C ~~~ Load\n",
    "    D ~~~ Present\n",
    "    \n",
    "    Extract -.->|fasta.gz| Transform\n",
    "    Transform -.->|pd.DataFrame| Load\n",
    "    Load -.->|string variables| Present"
   ],
   "id": "4ef504c2-8399-4012-906e-041b349d1517"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "This would be the data extraction phase of the DA pipeline.\n",
    "\n",
    "### Create Project Directory"
   ],
   "id": "1b01e189-00b0-4589-bcea-b755bfa6c2cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reticulate::source_python(\"00_Extract/scripts/directorize.py\")"
   ],
   "id": "416e0e08-37e9-4e4f-ae3a-f0e0338d33d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def directorize(base_path, structure):\n",
    "    \n",
    "    for dir_name, subdirs in structure.items():\n",
    "        dir_path = os.path.join(base_path, dir_name)\n",
    "        os.makedirs(dir_path, exist_ok = True)\n",
    "        \n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(dir_path, subdir)\n",
    "            os.makedirs(subdir_path, exist_ok = True)"
   ],
   "id": "fb40f3b1-60eb-4b2b-aae2-3b120ad19137"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory structure\n",
    "structure = {\n",
    "    \"00_Extract/\": [\"data/\", \"scripts/\"],\n",
    "    \"01_Transform/\": [\"data/\", \"scripts/\"],\n",
    "    \"02_Load/\": [\"data/\", \"scripts/\"],\n",
    "    \"03_Present/\": [\"data/\", \"scripts/\"]\n",
    "}\n",
    "\n",
    "# Create the analysis folder structure in a preferred base directory\n",
    "# \"\" = project's working directory\n",
    "directorize(\"\", structure)"
   ],
   "id": "4857f041-2f4d-4d00-922b-0a14d7c1ae6c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download to Local Machine"
   ],
   "id": "d557df9b-678c-49b3-97a8-2f46147a157e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reticulate::source_python(\n",
    "    \"00_Extract/scripts/importer.py\")"
   ],
   "id": "12035a8b-ba9e-4721-af78-da6133b176d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Import data from the web with wget\n",
    "import os\n",
    "import sys\n",
    "import wget\n",
    "\n",
    "def importer (fileMap):\n",
    "    # Download from URL to path and notify when complete\n",
    "    for url, file_path in fileMap.items():\n",
    "        # Checking file existence\n",
    "        if not os.path.exists(file_path):\n",
    "            wget.download(url, file_path)\n",
    "            print(f\"{file_path} written\")\n",
    "        else:\n",
    "            print(f\"{file_path} already exists.\")"
   ],
   "id": "102a1c51-7451-4b61-a427-fa3e8e696136"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "00_Extract/data/magicicada.fasta.gz already exists."
     ]
    }
   ],
   "source": [
    "# Set the url\n",
    "url = \"https://dnazoo.s3.wasabisys.com/Magicicada_septendecula/magicicada_hifiasm.asm.bp.p_ctg_HiC.fasta.gz\"\n",
    "\n",
    "# Set the local file path\n",
    "fpath = \"00_Extract/data/magicicada.fasta.gz\"\n",
    "\n",
    "# Map the url to the file path\n",
    "fileMap = {url: fpath}\n",
    "\n",
    "importer(fileMap)"
   ],
   "id": "0e48434b-899c-46b0-ab35-0476bcb35ce9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The specific link used to download all data from**\n",
    ">\n",
    "> <https://dnazoo.s3.wasabisys.com/Magicicada_septendecula/magicicada_hifiasm.asm.bp.p_ctg_HiC.fasta.gz>\n",
    "\n",
    "## Transform\n",
    "\n",
    "The data transformation phase of the pipeline.\n",
    "\n",
    "### Decompress .GZ"
   ],
   "id": "76bf2b4a-615b-4f53-923b-4f5a165a16a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reticulate::source_python(\"01_Transform/scripts/decompress.py\")"
   ],
   "id": "b48ab704-78f2-4328-9997-d99f9b7bc9b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Decompress the gz file with gzip\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def decompress(gzFasta, fasta):\n",
    "    \n",
    "    # If not decompressed, then decompress and redirect to a new file path\n",
    "    if not os.path.exists(fasta):\n",
    "        # File doesn't exist, then decompress\n",
    "        with gzip.open(gzFasta, 'rb') as f_in:\n",
    "            with open(fasta, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"{fasta} has been decompressed and written.\")\n",
    "    else:\n",
    "        print(f\"The file {fasta} already exists. Skipping unzip.\")"
   ],
   "id": "069fbec1-9c84-4547-91f6-95e31640ea57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The file 01_Transform/data/magicicada.fasta already exists. Skipping unzip."
     ]
    }
   ],
   "source": [
    "# Set the compressed fasta.gz file variable\n",
    "gzFasta = \"00_Extract/data/magicicada.fasta.gz\"\n",
    "\n",
    "# Set the decompressed fasta file variable\n",
    "fasta = \"01_Transform/data/magicicada.fasta\"\n",
    "\n",
    "# Pass file paths to the function\n",
    "decompress(gzFasta, fasta)"
   ],
   "id": "a94f022c-5752-4b0d-9368-aed5722358e7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk should be ran locally instead of with `quarto render`. When working with the source file, change the code-chunk language specifier from `{.bash}` back to `{bash}`. You might have to add the `{bash}` tag entirely to the div. Not sure how else to go about accomplishing this within my current Quarto project setup. \\[@trizna2020\\]\n",
    "\n",
    "``` bash\n",
    "# BASH SCRIPT\n",
    "\n",
    "# The uncompressed fasta file variable\n",
    "fasta=01_Transform/data/magicicada.fasta\n",
    "\n",
    "# The text file path variable generated by the script\n",
    "summary_stats=01_Transform/data/summary_stats.txt\n",
    "\n",
    "assembly_stats $fasta > $summary_stats\n",
    "```\n",
    "\n",
    "Transform the text file into a Python dataframe. I am opting to not to blanket change data-types as output format could vary by user preference."
   ],
   "id": "12c5d749-7dfe-4fbe-bdd0-3218a6659ede"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import  external python script to local library environment\n",
    "reticulate::source_python(\"01_Transform/scripts/assemblyFramer.py\")"
   ],
   "id": "32a907f9-ff44-4f57-8718-f5e86e11da19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Utilizes Python string methods and multi-indexing \n",
    "to process assembly_stats' output text file \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def assemblyFramer(statsPath = None):\n",
    "    \n",
    "    #---- Read Text File\n",
    "    with open(statsPath, 'r') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "    #---- Regex Matching\n",
    "    pairs = re.findall(r\"\\\"\\w+\\\"\\:\\s\\d*\\.?\\d*\", content)\n",
    "    \n",
    "    #---- Clean Strings\n",
    "    cleaned_list = [pair.replace('\"', '').replace(':', '').strip() for pair in pairs]\n",
    "    \n",
    "    #---- Split Strings\n",
    "    labeled_list = [item.split() for item in cleaned_list]\n",
    "    \n",
    "    #---- Create DataFrame\n",
    "    df = pd.DataFrame(labeled_list, columns = ['Label', 'Value'])\n",
    "    \n",
    "    #---- Add Category Column\n",
    "    df['Category'] = ['Contigs'] * 17 + ['Scaffolds'] * 17\n",
    "    \n",
    "    #---- Create Arrays\n",
    "    category_array = pd.Series.to_list(df['Category'])\n",
    "    label_array = pd.Series.to_list(df['Label'])\n",
    "    value_array = pd.Series.to_list(df['Value'])\n",
    "    \n",
    "    #---- Combine Arrays to List\n",
    "    arrayList = [category_array, label_array]\n",
    "    \n",
    "    #---- Define Multi-Level Indices\n",
    "    indices = pd.MultiIndex.from_arrays(arrays = arrayList, names = ('Category', 'Label'))\n",
    "    \n",
    "    #---- Index a DataFrame \n",
    "    df_indexed = pd.DataFrame(data = value_array, index = indices)\n",
    "    \n",
    "    #---- Rename Non-Indexed Column\n",
    "    df_indexed = df_indexed.rename(columns = {0:\"Value\"})\n",
    "    \n",
    "    return df_indexed"
   ],
   "id": "fb20e6d7-4607-4005-b1f2-2d071fcc50bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the local text file path\n",
    "statsPath = \"01_Transform/data/summary_stats.txt\"\n",
    "# Run to yield an multi-indexed dataframe\n",
    "df = assemblyFramer(statsPath)"
   ],
   "id": "991ed38f-476f-4126-bb62-d764cc3b156a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "This is the data loading phase. Following completion of this stage, querying the data should be more intuitive than before."
   ],
   "id": "6f645baa-9994-47ca-a0d6-0bb08d8443bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reticulate::source_python(\"02_Load/scripts/strint.py\")"
   ],
   "id": "bcd7b21b-8514-4a98-a970-c8005285e509"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Formats the string representation of an \n",
    "integer value as a comma separated string. \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Format output with comma seperator for thousands place\n",
    "def strint (dataframe, category, label):\n",
    "    \n",
    "    # Find the desired value\n",
    "    stat = dataframe.loc[(category, label), \"Value\"]\n",
    "    \n",
    "    # Set boolean match value\n",
    "    isFloat = re.search(r\"\\.\", stat)\n",
    "    \n",
    "    # Convert to float if there is a decimal\n",
    "    if isFloat:\n",
    "        stat = pd.to_numeric(stat, downcast = \"float\")\n",
    "    else:\n",
    "        # Else convert to an integer \n",
    "        stat = pd.to_numeric(stat, downcast = \"integer\")\n",
    "        \n",
    "    # Add a thousands seperator and convert back to a string\n",
    "    stat = f'{stat:,}'\n",
    "    \n",
    "    return stat "
   ],
   "id": "cfd1e04d-ea2d-4652-b7ec-dfe960989b33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Contigs\n",
    "ctig_len = strint(df, \"Contigs\", \"total_bps\")\n",
    "ctig_count = strint(df, \"Contigs\", \"sequence_count\")\n",
    "ctig_n50 = strint(df, \"Contigs\", \"N50\")\n",
    "ctig_max = strint(df, \"Contigs\", \"longest\")\n",
    "\n",
    "#---- Scaffolds\n",
    "sfld_len = strint(df, \"Scaffolds\", \"total_bps\")\n",
    "sfld_count = strint(df, \"Scaffolds\", \"sequence_count\")\n",
    "sfld_n50 = strint(df, \"Scaffolds\", \"N50\")\n",
    "sfld_max = strint(df, \"Scaffolds\", \"longest\")"
   ],
   "id": "bb88eb6c-772f-4ac5-a1ec-6fd3993e3189"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Python query syntax made easier**\n",
    ">\n",
    "> ``` python\n",
    "> # strint(dataframe, category, label)\n",
    "> ctig_len = strint(df, \"Contigs\", \"N50\")\n",
    ">\n",
    "> # --->> \n",
    ">\n",
    "> # Which then finds the desired value or 'Value'\n",
    "> stat = dataframe.loc[(category, label), \"Value\"]\n",
    "> ```\n",
    "\n",
    "## Present\n",
    "\n",
    "### The Pandas Table\n",
    "\n",
    "This is a slightly formatted view of the Pandas table designed to be more easily queried to return the desired statistic. If, however, you’d like to treat the Styler object as the unchanged, dataframe object, use the `forma_df.data` syntax.\n",
    "\n",
    "[:The original dataframe output:](#NutFrame)\n",
    "\n",
    "``` r\n",
    "reticulate::source_python(\"03_Present/scripts/formaFrame.py\")\n",
    "```\n",
    "\n",
    "``` python\n",
    "#---- Count Colors\n",
    "# Create color palettes for first level index and second level index + columns.\n",
    "n_colors1 = len(df.index.levels[0])\n",
    "n_colors2 = len(df.index.levels[1]) + len(df.columns)\n",
    "\n",
    "#---- Palettes\n",
    "# Adjust color palettes easily\n",
    "palette1 = sns.color_palette(\"Pastel2\", n_colors = n_colors1)\n",
    "palette2 = sns.color_palette(\"husl\", n_colors = n_colors2)\n",
    "\n",
    "#---- Palette-Index Dictionaries\n",
    "# Map index levels and column names to colors with dictionaries\n",
    "color_dict1 = dict(zip(df.index.levels[0], palette1))\n",
    "# For index level 2 and value columns, using a different palette\n",
    "color_dict2 = dict(zip(list(\n",
    "    df.index.levels[1]) + list(df.columns), palette2))\n",
    "\n",
    "#---- Call Function\n",
    "forma_df = formaFrame(df, color_dict1, color_dict2)\n",
    "\n",
    "#---- Hide Headers\n",
    "# The columns headers look a bit odd for display purposes\n",
    "forma_df = forma_df.hide(axis = \"index\", names = True)\n",
    "forma_df = forma_df.hide(axis = \"columns\", level = 0)\n",
    "\n",
    "#---- Display \n",
    "forma_df\n",
    "```\n",
    "\n",
    "<style type=\"text/css\">\n",
    "#T_440a4_row0_col0, #T_440a4_row17_col0 {\n",
    "  background-color: rgba(246, 112, 136, 0.2);\n",
    "}\n",
    "#T_440a4_row1_col0, #T_440a4_row18_col0 {\n",
    "  background-color: rgba(247, 117, 67, 0.2);\n",
    "}\n",
    "#T_440a4_row2_col0, #T_440a4_row19_col0 {\n",
    "  background-color: rgba(213, 140, 49, 0.2);\n",
    "}\n",
    "#T_440a4_row3_col0, #T_440a4_row20_col0 {\n",
    "  background-color: rgba(187, 151, 49, 0.2);\n",
    "}\n",
    "#T_440a4_row4_col0, #T_440a4_row21_col0 {\n",
    "  background-color: rgba(163, 159, 49, 0.2);\n",
    "}\n",
    "#T_440a4_row5_col0, #T_440a4_row22_col0 {\n",
    "  background-color: rgba(135, 167, 49, 0.2);\n",
    "}\n",
    "#T_440a4_row6_col0, #T_440a4_row23_col0 {\n",
    "  background-color: rgba(79, 176, 49, 0.2);\n",
    "}\n",
    "#T_440a4_row7_col0, #T_440a4_row24_col0 {\n",
    "  background-color: rgba(50, 176, 114, 0.2);\n",
    "}\n",
    "#T_440a4_row8_col0, #T_440a4_row25_col0 {\n",
    "  background-color: rgba(52, 174, 144, 0.2);\n",
    "}\n",
    "#T_440a4_row9_col0, #T_440a4_row26_col0 {\n",
    "  background-color: rgba(53, 172, 164, 0.2);\n",
    "}\n",
    "#T_440a4_row10_col0, #T_440a4_row27_col0 {\n",
    "  background-color: rgba(54, 170, 181, 0.2);\n",
    "}\n",
    "#T_440a4_row11_col0, #T_440a4_row28_col0 {\n",
    "  background-color: rgba(56, 168, 201, 0.2);\n",
    "}\n",
    "#T_440a4_row12_col0, #T_440a4_row29_col0 {\n",
    "  background-color: rgba(59, 163, 236, 0.2);\n",
    "}\n",
    "#T_440a4_row13_col0, #T_440a4_row30_col0 {\n",
    "  background-color: rgba(137, 148, 244, 0.2);\n",
    "}\n",
    "#T_440a4_row14_col0, #T_440a4_row31_col0 {\n",
    "  background-color: rgba(186, 130, 244, 0.2);\n",
    "}\n",
    "#T_440a4_row15_col0, #T_440a4_row32_col0 {\n",
    "  background-color: rgba(231, 102, 244, 0.2);\n",
    "}\n",
    "#T_440a4_row16_col0, #T_440a4_row33_col0 {\n",
    "  background-color: rgba(245, 99, 211, 0.2);\n",
    "}\n",
    "#T_440a4_level0_row0 {\n",
    "  background-color: rgba(179, 226, 205, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row0, #T_440a4_level1_row17 {\n",
    "  background-color: rgba(246, 112, 136, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row1, #T_440a4_level1_row18 {\n",
    "  background-color: rgba(247, 117, 67, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row2, #T_440a4_level1_row19 {\n",
    "  background-color: rgba(213, 140, 49, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row3, #T_440a4_level1_row20 {\n",
    "  background-color: rgba(187, 151, 49, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row4, #T_440a4_level1_row21 {\n",
    "  background-color: rgba(163, 159, 49, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row5, #T_440a4_level1_row22 {\n",
    "  background-color: rgba(135, 167, 49, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row6, #T_440a4_level1_row23 {\n",
    "  background-color: rgba(79, 176, 49, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row7, #T_440a4_level1_row24 {\n",
    "  background-color: rgba(50, 176, 114, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row8, #T_440a4_level1_row25 {\n",
    "  background-color: rgba(52, 174, 144, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row9, #T_440a4_level1_row26 {\n",
    "  background-color: rgba(53, 172, 164, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row10, #T_440a4_level1_row27 {\n",
    "  background-color: rgba(54, 170, 181, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row11, #T_440a4_level1_row28 {\n",
    "  background-color: rgba(56, 168, 201, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row12, #T_440a4_level1_row29 {\n",
    "  background-color: rgba(59, 163, 236, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row13, #T_440a4_level1_row30 {\n",
    "  background-color: rgba(137, 148, 244, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row14, #T_440a4_level1_row31 {\n",
    "  background-color: rgba(186, 130, 244, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row15, #T_440a4_level1_row32 {\n",
    "  background-color: rgba(231, 102, 244, 0.2);\n",
    "}\n",
    "#T_440a4_level1_row16, #T_440a4_level1_row33 {\n",
    "  background-color: rgba(245, 99, 211, 0.2);\n",
    "}\n",
    "#T_440a4_level0_row17 {\n",
    "  background-color: rgba(253, 205, 172, 0.2);\n",
    "}\n",
    "</style>\n",
    "\n",
    "  ----------- ---------------- --------------------\n",
    "  Contigs     L10              41\n",
    "              L20              99\n",
    "              L30              174\n",
    "              L40              267\n",
    "              L50              385\n",
    "              N10              12643769\n",
    "              N20              9681846\n",
    "              N30              7895799\n",
    "              N40              6288966\n",
    "              N50              4902968\n",
    "              gc_content       35.248103813419206\n",
    "              longest          43529772\n",
    "              mean             1552486.9914285715\n",
    "              median           331935.0\n",
    "              sequence_count   4200\n",
    "              shortest         1000\n",
    "              total_bps        6520445364\n",
    "  Scaffolds   L10              0\n",
    "              L20              0\n",
    "              L30              1\n",
    "              L40              2\n",
    "              L50              3\n",
    "              N10              1438277616\n",
    "              N20              1438277616\n",
    "              N30              915491830\n",
    "              N40              607508155\n",
    "              N50              518932092\n",
    "              gc_content       35.248103813419206\n",
    "              longest          1438277616\n",
    "              mean             3212576.533990148\n",
    "              median           62362.5\n",
    "              sequence_count   2030\n",
    "              shortest         1000\n",
    "              total_bps        6521530364\n",
    "  ----------- ---------------- --------------------\n",
    "\n",
    "### DNA Zoo’s Table, Reproduced"
   ],
   "id": "23539f82-9a11-4765-965c-5c7159963210"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)"
   ],
   "id": "89c672ee-7a38-4f42-95fc-a850f4582d87"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the library makes the code a little bit cleaner for inserting the values into the table below. For example, I would have had to type 4,902,968, but now I can just type 4,902,968 into the individual cells. I needed to convert the values into r objects, as the knitr engine used in rendering this document does not seem display output from execution of inline Python code directly.\n",
    "\n",
    "|  |  |  |  |\n",
    "|------------------|------------------|------------------|-------------------|\n",
    "| **Contig length (bp)** | **Number of contigs** | **Contig N50 (bp)** | **Longest contig (bp)** |\n",
    "| 6,520,445,364 | 4,200 | 4,902,968 | 43,529,772 |\n",
    "| **Scaffold length (bp)** | **Number of scaffolds** | **Scaffold N50 (bp)** | **Longest scaffold (bp)** |\n",
    "| 6,521,530,364 | 2,030 | 518,932,092 | 1,438,277,616 |\n",
    "\n",
    "## :x NutFrame"
   ],
   "id": "aa75552c-7731-475f-8de4-d4866abcd726"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                       Value\n",
      "Category  Label                             \n",
      "Contigs   L10                             41\n",
      "          L20                             99\n",
      "          L30                            174\n",
      "          L40                            267\n",
      "          L50                            385\n",
      "          N10                       12643769\n",
      "          N20                        9681846\n",
      "          N30                        7895799\n",
      "          N40                        6288966\n",
      "          N50                        4902968\n",
      "          gc_content      35.248103813419206\n",
      "          longest                   43529772\n",
      "          mean            1552486.9914285715\n",
      "          median                    331935.0\n",
      "          sequence_count                4200\n",
      "          shortest                      1000\n",
      "          total_bps               6520445364\n",
      "Scaffolds L10                              0\n",
      "          L20                              0\n",
      "          L30                              1\n",
      "          L40                              2\n",
      "          L50                              3\n",
      "          N10                     1438277616\n",
      "          N20                     1438277616\n",
      "          N30                      915491830\n",
      "          N40                      607508155\n",
      "          N50                      518932092\n",
      "          gc_content      35.248103813419206\n",
      "          longest                 1438277616\n",
      "          mean             3212576.533990148\n",
      "          median                     62362.5\n",
      "          sequence_count                2030\n",
      "          shortest                      1000\n",
      "          total_bps               6521530364"
     ]
    }
   ],
   "source": [
    "# A simple call on the Styler object\n",
    "forma_df.data"
   ],
   "id": "603e3d14-991f-4f1a-93a8-f8136d4fd2d0"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
